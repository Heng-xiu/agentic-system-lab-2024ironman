{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🥱 LangChain 與 LangGraph 串流技術深度探索\n",
        "\n",
        "在這個教程中，我們將深入探討 LangChain 和 LangGraph 的串流（Streaming）功能，這對於打造反應靈敏的 AI 應用至關重要。本指南假設您已熟悉以下概念：\n",
        "\n",
        "- 聊天模型（Chat models）\n",
        "- LangChain 表達語言（LangChain Expression Language）\n",
        "- 輸出解析器（Output parsers）\n",
        "\n",
        "❤️ Created by [hengshiousheu](https://huggingface.co/Heng666).\n"
      ],
      "metadata": {
        "id": "A76vheUhpdRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 為什麼串流如此重要？\n",
        "\n",
        "在基於大型語言模型（LLM）的應用中，串流技術扮演著舉足輕重的角色。它能夠顯著提升用戶體驗，讓應用感覺更加靈敏和即時。\n",
        "\n",
        "LangChain 中的核心元素，如聊天模型、輸出解析器、提示模板、檢索器和代理等，都實現了 LangChain 可運行接口（Runnable Interface）。這個接口提供了兩種主要的串流方法：\n",
        "\n",
        "1. `sync stream` 和 `async astream`：這是默認的串流實現，用於串流鏈條的最終輸出。\n",
        "2. async `astream_events` 和 async `astream_log`：這些方法能夠串流中間步驟和最終輸出。\n",
        "\n",
        "\n",
        "[相關文件:LangChain/How-to-Guides/How to stream runnables](https://python.langchain.com/v0.2/docs/how_to/streaming/)\n",
        "\n",
        "接下來，我們將深入探討這兩種方法，並學習如何靈活運用它們。\n"
      ],
      "metadata": {
        "id": "DdCRM1NCqKeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [技術亮點] LangChain 的串流功能不僅提高了應用的響應速度，還能讓開發者更靈活地處理和展示 AI 生成的內容。"
      ],
      "metadata": {
        "id": "YMrQzhRvqcxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 環境建置\n",
        "\n",
        "在開始我們的探索之前，讓我們先搭建實驗環境。\n",
        "\n",
        "## 安裝套件包\n",
        "\n",
        "在深入之前，我們需要先搭建實驗環境。\n",
        "\n",
        "以下是所需的套件安裝命令："
      ],
      "metadata": {
        "id": "yIDFLR87UT8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD8K059JBbSJ"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet langchain\n",
        "%pip install --quiet langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "NoX2ankTMlk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 實用提示：確保所有環境變數都正確設置，這對於順利運行後續程式碼至關重要。"
      ],
      "metadata": {
        "id": "rF8PDWKKUQwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 深入了解 Chat Model 的互動機制\n",
        "\n",
        "為了簡化自定義鏈的創建過程，LangChain 實現了一個\"可運行\"（Runnable）協議。許多 LangChain 組件都實現了這個協議，包括聊天模型、LLM、輸出解析器、檢索器、提示模板等。\n",
        "\n",
        "這個標準接口使得定義和調用自定義鏈變得簡單直接。主要包括以下方法：\n",
        "\n",
        "- `stream`：串流回應的片段\n",
        "- `invoke`：對輸入調用鏈\n",
        "- `batch`：對輸入列表調用鏈\n",
        "\n",
        "所有的 Runnable 物件都實作了一個同步方法 `stream` 和一個異步變體 `astream`。\n",
        "\n",
        "這些方法旨在以分塊(Chunk)形式串流最終輸出，並在每個塊可用時立即生成。\n",
        "\n",
        "[相關文件：LangChain Runnable interface](https://python.langchain.com/v0.1/docs/expression_language/interface/)"
      ],
      "metadata": {
        "id": "u1bBJHDXVWx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 同步調用：invoke 方法解析\n",
        "\n",
        "`invoke()` 方法是最直接的使用方式，會在模型生成完整回應後才返回完整結果。讓我們看一個實際例子："
      ],
      "metadata": {
        "id": "CdKmWCDLprBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "model.invoke(\"請你講一個早安問候語\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HogFz_dWOfTC",
        "outputId": "e8b93221-fb7b-4e84-8eae-424e0636baeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='早安，願你今天充滿活力與快樂！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 25, 'total_tokens': 48}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-93754cf7-50b4-4a99-b2d0-0fcdd42f620e-0', usage_metadata={'input_tokens': 25, 'output_tokens': 23, 'total_tokens': 48})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [技術說明] invoke() 方法適用於對實時性要求不高的場景，或當您需要一次性獲取完整回應時使用。"
      ],
      "metadata": {
        "id": "5YxhuTQ3tN2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stream 方法的魅力\n",
        "\n",
        "相比之下，stream() 方法允許我們在生成過程中逐步獲取回應，這對提升用戶體驗至關重要。`stream()` 方法返回一個生成器，能夠在生成過程中逐步產生 token。\n",
        "\n",
        "串流處理的實現需要程序中的每個步驟都能夠處理輸入流。這意味著每個組件都要能夠一次處理一個輸入塊，並生成相應的輸出塊。這種處理方式帶來了獨特的優勢和挑戰：\n",
        "\n",
        "1. 連續性處理：串流允許系統在接收到完整輸入之前就開始處理和輸出，大大提高了響應速度和效率。\n",
        "2. 複雜度變化：串流處理的複雜度可能差異很大：\n",
        " - 簡單任務：如直接輸出 LLM 生成的 token。\n",
        " - 複雜任務：如在 JSON 結果完全生成之前就開始串流其部分內容。\n",
        "3. 靈活性與挑戰：這種方法提供了極大的靈活性，但也帶來了編程上的挑戰，特別是在處理結構化數據或需要整體上下文的任務時。\n",
        "4. 最佳起點：要開始探索串流技術，最好的切入點就是 LLM 應用中最核心的組件——LLM 本身。這是因為 LLM 天生就適合token級別的串流輸出。\n",
        "\n",
        "> [技術要點] 串流的關鍵在於程序中的每個步驟都能夠處理輸入流，即一次處理一個輸入塊，並生成相應的輸出塊。它要求開發者重新思考數據處理流程，從整體處理轉向增量處理。"
      ],
      "metadata": {
        "id": "wKvvzezkpz0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.invoke(\"請你講一個早安問候語\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGH37k2WOu63",
        "outputId": "41e6f3be-7014-45e0-de07-b1ff5579176c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='早安！祝你今天充滿活力和快樂！' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 25, 'total_tokens': 47}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-2d823c99-fe70-4a48-b532-eed8e18ef391-0' usage_metadata={'input_tokens': 25, 'output_tokens': 22, 'total_tokens': 47}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.stream(\"請你講一個早安問候語\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N098RMJJO1mW",
        "outputId": "891844b8-9cf6-4c21-da75-b1e8073e7bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object BaseChatModel.stream at 0x7b5bdde0cba0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果您在異步環境中工作，可以考慮使用異步的 `astream` API："
      ],
      "metadata": {
        "id": "HTn89e3KqOQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "async for chunk in model.astream(\"請你告訴我 k8s 跟 docker 區別\"):\n",
        "    chunks.append(chunk)\n",
        "    print(chunk.content, end=\"|\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15rViIbsO_H6",
        "outputId": "9e60c14f-c082-4674-e828-06bc8232f63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|K|ubernetes|（|簡|稱| k|8|s|）|和| Docker| 是|兩|個|不|同|的|容|器|技|術|。\n",
            "\n",
            "|D|ocker| 是|一|個|開|源|的|容|器|化|平|台|，|可以|將|應|用|程序|和|其|相|關|的|依|賴|項|打|包|成|一|個|獨|立|的|容|器|，|使|其|可以|在|任|何|環|境|中|運|行|。|D|ocker| 提|供|了|一|個|輕|量|級|的|容|器|化|解|決|方|案|，|使|開|發|人|員|可以|更|容|易|地|部|署|和|管理|應|用|程序|。\n",
            "\n",
            "|K|ubernetes| 是|一|個|開|源|的|容|器|管理|平|台|，|用|於|自|動|化|部|署|、|擴|展|和|管理|容|器|化|應|用|程序|。|K|ubernetes| 可|以|管理|多|個| Docker| 容|器|，|並|提|供|了|許|多|功能|，|如|自|動|擴|展|、|負|載|均|衡|、|服|務|發|現|等|，|使|容|器|化|應|用|程序|更|容|易|在|生|產|環|境|中|運|行|。\n",
            "\n",
            "|總|的|來|說|，|D|ocker| 是|一|個|容|器|化|平|台|，|而| Kubernetes| 是|一|個|容|器|管理|平|台|，|它|們|可以|一|起|使用|，|但|各|自|擁|有|不|同|的|功能|和|用|途|。||"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [實用技巧] 使用 end=\"|\" 和 flush=True 可以實現平滑的輸出效果，讓用戶感受到實時生成的過程。"
      ],
      "metadata": {
        "id": "0SQV86fstZlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEghmv3wZjZj",
        "outputId": "f593aa2d-acad-4617-d523-4b7b5534bd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessageChunk(content='K', id='run-d78fce95-17a8-4d0f-aeb4-2c9be1e950e8')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmLe_-7DPSbM",
        "outputId": "ead3992e-c037-4302-c700-a9126f590e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessageChunk(content='ubernetes', id='run-d78fce95-17a8-4d0f-aeb4-2c9be1e950e8')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[1] + chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8zazLBgZnxd",
        "outputId": "88b9348c-2d8a-4fff-9f99-b1db125bbeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessageChunk(content='Kubernetes', id='run-d78fce95-17a8-4d0f-aeb4-2c9be1e950e8')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [注意] 我們得到的是 `AIMessageChunk` 對象。這些塊在設計上是可累加的——只需簡單地將它們相加，就能得到到目前為止的完整響應狀態！"
      ],
      "metadata": {
        "id": "xfXXwkm-r7M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in model.stream(\"寫一首關於 k8s 的兒歌\"):\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGuEc4u8PYop",
        "outputId": "fb094132-f51a-4d95-cebf-9e6139c0116f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K8s 是個神奇的軟體，\n",
            "讓我們的應用更加完美。\n",
            "它像個小管家，\n",
            "幫助我們管理容器。\n",
            "\n",
            "K8s，K8s，快來幫我們，\n",
            "讓我們的應用更加強大。\n",
            "K8s，K8s，我們愛你，\n",
            "讓我們的系統更加穩定。\n",
            "\n",
            "K8s像一位巫師，\n",
            "讓我們的應用飛速運行。\n",
            "它就像一座城堡，\n",
            "保護著我們的程式碼。\n",
            "\n",
            "K8s，K8s，你是最棒的，\n",
            "讓我們的應用更加完美。\n",
            "K8s，K8s，我們感謝你，\n",
            "讓我們的系統更加順暢。"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 結合 LangChain 表達語言（LCEL）實現持續串流回應\n",
        "\n",
        "現在，讓我們將 Prompt、Model 和 OutputParser 結合起來，驗證串流效果。\n",
        "\n",
        "> [技術焦點] 我們將使用 StrOutputParser 來解析模型的輸出。這是一個簡單的解析器，它從 AIMessageChunk 中提取內容字段，給我們模型返回的 token。"
      ],
      "metadata": {
        "id": "QLHagWsRZ-jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"講一個早安問候語關於 {topic}\")\n",
        "parser = StrOutputParser()\n",
        "chain = prompt | model | parser\n",
        "\n",
        "async for chunk in chain.astream({\"topic\": \"父母親\"}):\n",
        "    print(chunk, end=\"|\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ybETGiaSk8",
        "outputId": "7763cc4e-d4b8-42da-aa30-d2aebd5f0694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|早|安|！|父|母|親|，|感|謝|您|們|無|私|的|愛|與|付|出|，|願|您|們|今|天|充|滿|幸|福|與|快|樂|！||"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [提示] LCEL 是一種聲明式方法，用於通過鏈接不同的 LangChain 原語來指定\"程序\"。使用 LCEL 創建的鏈條會自動實現 stream 和 astream，允許串流最終輸出。"
      ],
      "metadata": {
        "id": "SBuJLQg5aOn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> StrOutputParser 用途就是把 Chunk 當中 content 提出=="
      ],
      "metadata": {
        "id": "OHX1x19VaiLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 探索 `Stream_Events` 高級串流技術\n",
        "\n",
        "Event Streaming 是一個 beta API，可能會根據反饋進行調整。本指南演示的是 V2 API，需要 langchain-core >= 0.2 版本。如果要使用 V1 API 的話需要參考[舊版 LangChain 官方文件](https://python.langchain.com/v0.1/docs/expression_language/streaming/#using-stream-events)\n",
        "\n",
        "[langChain v0.2 Concepts/Streaming 文件連結](https://python.langchain.com/v0.2/docs/concepts/#streaming)\n"
      ],
      "metadata": {
        "id": "-HVhKjy5a-lQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[版本提醒] 確保您使用的是最新版本的 LangChain："
      ],
      "metadata": {
        "id": "lJ0PPg-nsbhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_core\n",
        "\n",
        "langchain_core.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T6A-g6OGa-YW",
        "outputId": "df53b0f8-c4d8-4baf-ac5f-e7c4be4ac961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.2.33'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "為了讓 `astream_events` API 正常工作，請注意以下幾點：\n",
        "\n",
        "- 盡可能在整個代碼中使用 `async`（例如，異步工具等）\n",
        "- 在定義自定義函數/ runnalbes 時傳播 callbacks\n",
        "- 當不使用 LCEL 而使用可運行對象時，確保調用 LLM 的 `.astream()` 而不是 `.ainvoke`，以強制 LLM 串流 token\n"
      ],
      "metadata": {
        "id": "TClYP4m4btnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stream_Events 事件參考指南\n",
        "\n",
        "以下是各種 Runnable 物件 可能發出的一些事件的參考表：\n"
      ],
      "metadata": {
        "id": "Iq_F-LWUb25D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| event                | name             | chunk                           | input                                         | output                                          |\n",
        "|----------------------|------------------|---------------------------------|-----------------------------------------------|-------------------------------------------------|\n",
        "| on_chat_model_start  | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} |                                                 |\n",
        "| on_chat_model_stream | [model name]     | AIMessageChunk(content=\"hello\") |                                               |                                                 |\n",
        "| on_chat_model_end    | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} | AIMessageChunk(content=\"hello world\")           |\n",
        "| on_llm_start         | [model name]     |                                 | {'input': 'hello'}                            |                                                 |\n",
        "| on_llm_stream        | [model name]     | 'Hello'                         |                                               |                                                 |\n",
        "| on_llm_end           | [model name]     |                                 | 'Hello human!'                                |                                                 |\n",
        "| on_chain_start       | format_docs      |                                 |                                               |                                                 |\n",
        "| on_chain_stream      | format_docs      | \"hello world!, goodbye world!\"  |                                               |                                                 |\n",
        "| on_chain_end         | format_docs      |                                 | [Document(...)]                               | \"hello world!, goodbye world!\"                  |\n",
        "| on_tool_start        | some_tool        |                                 | {\"x\": 1, \"y\": \"2\"}                            |                                                 |\n",
        "| on_tool_end          | some_tool        |                                 |                                               | {\"x\": 1, \"y\": \"2\"}                              |\n",
        "| on_retriever_start   | [retriever name] |                                 | {\"query\": \"hello\"}                            |                                                 |\n",
        "| on_retriever_end     | [retriever name] |                                 | {\"query\": \"hello\"}                            | [Document(...), ..]                             |\n",
        "| on_prompt_start      | [template_name]  |                                 | {\"question\": \"hello\"}                         |                                                 |\n",
        "| on_prompt_end        | [template_name]  |                                 | {\"question\": \"hello\"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |\n"
      ],
      "metadata": {
        "id": "o-43Sfj9cc0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [注意] 當串流正確實現時，可運行對象的輸入直到輸入流完全消耗後才能知道。這意味著輸入通常只包含在結束事件中，而不是開始事件中。"
      ],
      "metadata": {
        "id": "w00xpGI6syHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 從 Chat Model(聊天模型) 了解運作機制\n",
        "\n",
        "讓我們來看看聊天模型產生的事件：\n"
      ],
      "metadata": {
        "id": "OWO8YluPcmS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events = []\n",
        "async for event in model.astream_events(\"早安\", version=\"v2\"):\n",
        "    events.append(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmuvLwKhczSQ",
        "outputId": "b56638ac-3ea1-4aee-f2e4-cca87bdf5f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
            "  warn_beta(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "讓我們看看前幾個事件和最後幾個事件。"
      ],
      "metadata": {
        "id": "gBM2EC6Ec4DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rich\n",
        "rich.print(events[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "AaA9cKQpc5Y2",
        "outputId": "eef7ee8e-74e7-4613-8be1-68cce3811f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_start'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'input'\u001b[0m: \u001b[32m'早安'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_stream'\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'chunk'\u001b[0m: \u001b[1;35mAIMessageChunk\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m, \u001b[33mid\u001b[0m=\u001b[32m'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_stream'\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'chunk'\u001b[0m: \u001b[1;35mAIMessageChunk\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'早'\u001b[0m, \u001b[33mid\u001b[0m=\u001b[32m'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_start'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'早安'</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_stream'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'chunk'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessageChunk</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span><span style=\"font-weight: bold\">)}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_stream'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'chunk'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessageChunk</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'早'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span><span style=\"font-weight: bold\">)}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rich.print(events[-2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "f78L4uBcdCBg",
        "outputId": "612105bb-146d-49ae-8f8d-80eb2d9cf8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_stream'\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'chunk'\u001b[0m: \u001b[1;35mAIMessageChunk\u001b[0m\u001b[1m(\u001b[0m\n",
              "                \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
              "                \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m, \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo-0125'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                \u001b[33mid\u001b[0m=\u001b[32m'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m\n",
              "            \u001b[1m)\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_end'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'output'\u001b[0m: \u001b[1;35mAIMessageChunk\u001b[0m\u001b[1m(\u001b[0m\n",
              "                \u001b[33mcontent\u001b[0m=\u001b[32m'早安！祝您有美好的一天。'\u001b[0m,\n",
              "                \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m, \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo-0125'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                \u001b[33mid\u001b[0m=\u001b[32m'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m\n",
              "            \u001b[1m)\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_stream'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'chunk'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessageChunk</span><span style=\"font-weight: bold\">(</span>\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span><span style=\"font-weight: bold\">}</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>\n",
              "            <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_end'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessageChunk</span><span style=\"font-weight: bold\">(</span>\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'早安！祝您有美好的一天。'</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span><span style=\"font-weight: bold\">}</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>\n",
              "            <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2cdfdc79-1ec3-4682-9240-6faad3c2a9c5'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event_types = {event[\"event\"] for event in events}\n",
        "print(\"拉出存在的 event types:\", event_types)"
      ],
      "metadata": {
        "id": "fJ9WTmOrftKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以注意到回傳 Message 當中不同 Chunk 所在的 event 是不同的，從一開始 `on_chat_model_start`, `on_chat_model_stream`, 到最後 `on_chat_model_end`"
      ],
      "metadata": {
        "id": "gYwID9YWdJFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "整理一下輸出好方便識別\n"
      ],
      "metadata": {
        "id": "TZx3aPzkdpbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async for event in model.astream_events(\"早安\", version=\"v2\"):\n",
        "    event_type = event[\"event\"]\n",
        "    if event_type ==\"on_chat_model_start\":\n",
        "        print(\"Streamgin Start\", flush=False)\n",
        "    if event_type == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "          # 要考慮一下回傳沒有的情況\n",
        "          print(content, end=\"|\", flush=False)\n",
        "    if event_type == \"on_chat_model_end\":\n",
        "        print(\"\\nStreamgin End\", flush=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU7aPXukdvx2",
        "outputId": "c43cd7da-b37e-4e8d-b369-5743321c9a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamgin Start\n",
            "早|安|！|祝|您|今|天|过|得|愉|快|！|\n",
            "Streamgin End\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結合 Parser 處理串流輸出格式\n",
        "\n",
        "讓我們重新審視使用串流輸出解析器的鏈條示例，探索串流事件 API："
      ],
      "metadata": {
        "id": "E9pKgh9QeYjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"講一個早安問候語關於 {topic}\")\n",
        "parser = StrOutputParser()\n",
        "chain = prompt | model | parser\n",
        "\n",
        "parser_events = []\n",
        "async for event in chain.astream_events({\"topic\": \"父母親\"}, version=\"v2\"):\n",
        "    parser_events.append(event)"
      ],
      "metadata": {
        "id": "8vkGI7uOej1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you examine at the first few events, you'll notice that there are 3 different start events rather than 2 start events.\n",
        "\n",
        "The three start events correspond to:\n",
        "\n",
        "1. The chain (model + parser)\n",
        "2. The model\n",
        "3. The parser"
      ],
      "metadata": {
        "id": "us9X70cFe78_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "讓我們來觀察前六比事件。"
      ],
      "metadata": {
        "id": "nBV7D0lruFDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rich.print(parser_events[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lo42msMae-fN",
        "outputId": "6df38bba-4edd-46f1-9b7c-378e2255a658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chain_start'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'父母親'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'RunnableSequence'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'a09e4434-073d-402b-a9d2-e1d25c7c07d3'\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_prompt_start'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'父母親'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatPromptTemplate'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'seq:step:1'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'4d16c3de-b120-4da2-9641-fc6e5cd18da8'\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a09e4434-073d-402b-a9d2-e1d25c7c07d3'\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_prompt_end'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'output'\u001b[0m: \u001b[1;35mChatPromptValue\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'講一個早安問候語關於 父母親'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "            \u001b[32m'input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'父母親'\u001b[0m\u001b[1m}\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'4d16c3de-b120-4da2-9641-fc6e5cd18da8'\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatPromptTemplate'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'seq:step:1'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a09e4434-073d-402b-a9d2-e1d25c7c07d3'\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_start'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'講一個早安問候語關於 父母親'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'seq:step:2'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'd34c2887-eb15-4d62-b036-cace575d8906'\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a09e4434-073d-402b-a9d2-e1d25c7c07d3'\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_chat_model_stream'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'chunk'\u001b[0m: \u001b[1;35mAIMessageChunk\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m, \u001b[33mid\u001b[0m=\u001b[32m'run-d34c2887-eb15-4d62-b036-cace575d8906'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'd34c2887-eb15-4d62-b036-cace575d8906'\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'ChatOpenAI'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'seq:step:2'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'ls_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
              "            \u001b[32m'ls_model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
              "            \u001b[32m'ls_model_type'\u001b[0m: \u001b[32m'chat'\u001b[0m,\n",
              "            \u001b[32m'ls_temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a09e4434-073d-402b-a9d2-e1d25c7c07d3'\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'event'\u001b[0m: \u001b[32m'on_parser_start'\u001b[0m,\n",
              "        \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'StrOutputParser'\u001b[0m,\n",
              "        \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'seq:step:3'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[32m'run_id'\u001b[0m: \u001b[32m'827de03d-5d20-4d6a-a6f2-b3455a873859'\u001b[0m,\n",
              "        \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'parent_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a09e4434-073d-402b-a9d2-e1d25c7c07d3'\u001b[0m\u001b[1m]\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chain_start'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'父母親'</span><span style=\"font-weight: bold\">}}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'RunnableSequence'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a09e4434-073d-402b-a9d2-e1d25c7c07d3'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_prompt_start'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'父母親'</span><span style=\"font-weight: bold\">}}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatPromptTemplate'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'seq:step:1'</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4d16c3de-b120-4da2-9641-fc6e5cd18da8'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a09e4434-073d-402b-a9d2-e1d25c7c07d3'</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_prompt_end'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'講一個早安問候語關於 父母親'</span><span style=\"font-weight: bold\">)])</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'父母親'</span><span style=\"font-weight: bold\">}</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4d16c3de-b120-4da2-9641-fc6e5cd18da8'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatPromptTemplate'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'seq:step:1'</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a09e4434-073d-402b-a9d2-e1d25c7c07d3'</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_start'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'講一個早安問候語關於 父母親'</span><span style=\"font-weight: bold\">)]]}}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'seq:step:2'</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'d34c2887-eb15-4d62-b036-cace575d8906'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a09e4434-073d-402b-a9d2-e1d25c7c07d3'</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_chat_model_stream'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'chunk'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessageChunk</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-d34c2887-eb15-4d62-b036-cace575d8906'</span><span style=\"font-weight: bold\">)}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'d34c2887-eb15-4d62-b036-cace575d8906'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'seq:step:2'</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'ls_temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a09e4434-073d-402b-a9d2-e1d25c7c07d3'</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'event'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_parser_start'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'StrOutputParser'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'seq:step:3'</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'827de03d-5d20-4d6a-a6f2-b3455a873859'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'parent_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a09e4434-073d-402b-a9d2-e1d25c7c07d3'</span><span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "當我們仔細檢視事件流的開始部分時，會發現一個有趣的現象：出現了三個不同的開始事件，而不是預期的兩個。這三個開始事件分別對應於：\n",
        "\n",
        "1. 整個鏈條（模型 + 解析器）的啟動 `on_chain_start`\n",
        "2. 模型的初始化\n",
        "3. 解析器的準備階段 `on_prompt_start`"
      ],
      "metadata": {
        "id": "pTe5VSxzuM2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "這種層次化的事件結構反映了整個處理流程的組織方式，讓我們能夠精確地追蹤每個組件的運作狀態。\n",
        "\n",
        "讓我們通過實際操作來探索這個 API，特別關注模型和解析器的串流事件。為了聚焦於核心過程，我們將忽略開始事件、結束事件以及整個鏈條的事件。"
      ],
      "metadata": {
        "id": "_PXJxUSvgs98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_events = 0\n",
        "\n",
        "async for event in chain.astream_events(\n",
        "    {\"topic\": \"父母親\"},\n",
        "    version=\"v2\",\n",
        "):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        print(\n",
        "            f\"模型輸出 chunk: {repr(event['data']['chunk'].content)}\",\n",
        "            flush=True,\n",
        "        )\n",
        "    if kind == \"on_parser_stream\":\n",
        "        print(f\"解析器輸出 chunk: {event['data']['chunk']}\", flush=True)\n",
        "    num_events += 1\n",
        "    if num_events > 30:\n",
        "        # Truncate the output\n",
        "        print(\"...\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY1MAiR7hGkx",
        "outputId": "536344cb-9596-4b6d-8109-e424d21b95d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat model chunk: ''\n",
            "Parser chunk: \n",
            "Chat model chunk: '早'\n",
            "Parser chunk: 早\n",
            "Chat model chunk: '安'\n",
            "Parser chunk: 安\n",
            "Chat model chunk: '，'\n",
            "Parser chunk: ，\n",
            "Chat model chunk: '親'\n",
            "Parser chunk: 親\n",
            "Chat model chunk: '愛'\n",
            "Parser chunk: 愛\n",
            "Chat model chunk: '的'\n",
            "Parser chunk: 的\n",
            "Chat model chunk: '爸'\n",
            "Parser chunk: 爸\n",
            "Chat model chunk: '媽'\n",
            "Parser chunk: 媽\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[技術洞察]\n",
        "\n",
        "1. 事件分層：這種分層結構使我們能夠分別監控和分析鏈條、模型和解析器的行為。\n",
        "2. 實時追蹤：通過觀察 \"on_chat_model_stream\" 和 \"on_parser_stream\" 事件，我們可以實時跟蹤生成過程和解析過程。\n",
        "3. 性能優化機會：這種細粒度的事件流為性能分析和優化提供了寶貴的數據源。"
      ],
      "metadata": {
        "id": "0rZ9hlcKuoXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事件過濾技巧\n",
        "\n",
        "\n",
        "由於這個 API 產生了大量事件，能夠過濾事件變得非常有用。你可以按組件 `name`、組件 `tags` 或組件 `type` 進行過濾。"
      ],
      "metadata": {
        "id": "YbOoEdJgh4eW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 按類型(type)過濾"
      ],
      "metadata": {
        "id": "yLLLLIQziBQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_events = 0\n",
        "async for event in chain.astream_events(\n",
        "    {\"topic\": \"父母親\"},\n",
        "    version=\"v2\",\n",
        "    include_types=[\"chat_model\"],\n",
        "):\n",
        "    print(event)\n",
        "    max_events += 1\n",
        "    if max_events > 10:\n",
        "        # Truncate output\n",
        "        print(\"...\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKXSfwdKiGEs",
        "outputId": "7db03f43-21eb-47f3-e2ed-dba0e6015911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'event': 'on_chat_model_start', 'data': {'input': {'topic': '父母親'}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='早', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='安', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='！', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='感', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='謝', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='父', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='母', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='親', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='的', id='run-f3aec1d4-3d28-4947-be79-a7c9b61bca8b')}, 'run_id': 'f3aec1d4-3d28-4947-be79-a7c9b61bca8b', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['a5a69b8c-3b5f-453e-ac1f-8fabe0603edc']}\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [提示] 注意事件名稱通常是 `on_XXX_[start/stream/end]` 這樣的格式，但在示例中只寫了 chat_model。這是因為內部過濾器會提取 XXX 部分。\n"
      ],
      "metadata": {
        "id": "k6eQEW6XiYiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "讓我們嘗試一次擷取多個類型："
      ],
      "metadata": {
        "id": "t0LWVoGyttOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_events = 0\n",
        "async for event in chain.astream_events(\n",
        "    {\"topic\": \"父母親\"},\n",
        "    version=\"v2\",\n",
        "    include_types=[\"chat_model\", \"prompt\"],\n",
        "):\n",
        "    print(event)\n",
        "    max_events += 1\n",
        "    if max_events > 10:\n",
        "        # Truncate output\n",
        "        print(\"...\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D99QcdDSi8UH",
        "outputId": "41afd945-e734-4d2d-9c66-57ce574cc41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'event': 'on_prompt_start', 'data': {'input': {'topic': '父母親'}}, 'name': 'ChatPromptTemplate', 'tags': ['seq:step:1'], 'run_id': '04af2458-f973-446c-88a4-a0bf61187aa0', 'metadata': {}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_prompt_end', 'data': {'output': ChatPromptValue(messages=[HumanMessage(content='講一個早安問候語關於 父母親')])}, 'run_id': '04af2458-f973-446c-88a4-a0bf61187aa0', 'name': 'ChatPromptTemplate', 'tags': ['seq:step:1'], 'metadata': {}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='講一個早安問候語關於 父母親')]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='早', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='安', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='！', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='感', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='恩', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='父', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='母', id='run-c85f138c-93fb-46be-8b2e-de02dba65160')}, 'run_id': 'c85f138c-93fb-46be-8b2e-de02dba65160', 'name': 'ChatOpenAI', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['aa8e7717-51a9-49d6-82e2-795e63063810']}\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 證明是只拿 XXX 而已"
      ],
      "metadata": {
        "id": "I0lgfWyYi-2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 綜合過濾：按類型(type)、名稱(name)和標籤(tags)\n",
        "\n",
        "你也可以將三者 by name, by tags, by type 一起混著使用，這通常在串連較多 Chain 場合下使用，下面只展示如何丟入使用"
      ],
      "metadata": {
        "id": "6_J1qhGmjY6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"講一個早安問候語關於 {topic}\")\n",
        "model = model.with_config({\"run_name\": \"OAI_MODEL_GPT3.5\"})\n",
        "parser = StrOutputParser().with_config({\"run_name\": \"my_str_parser\"})\n",
        "\n",
        "chain = prompt | model | parser\n",
        "\n",
        "max_events = 0\n",
        "async for event in chain.astream_events(\n",
        "    {\"topic\": \"父母親\"},\n",
        "    version=\"v2\",\n",
        "    include_names=[\"OAI_MODEL_GPT3.5\"],\n",
        "    include_types=[\"chat_model\", \"prompt\"],\n",
        "    include_tags=[\"my_str_parser\"],\n",
        "):\n",
        "    print(event)\n",
        "    max_events += 1\n",
        "    if max_events > 10:\n",
        "        # Truncate output\n",
        "        print(\"...\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bt_2UcIjYHJ",
        "outputId": "cc786544-d6e9-4bd2-c94a-6f82f72d1ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'event': 'on_prompt_start', 'data': {'input': {'topic': '父母親'}}, 'name': 'ChatPromptTemplate', 'tags': ['seq:step:1'], 'run_id': 'b09f31c9-63e0-4486-bf54-f08827a01404', 'metadata': {}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_prompt_end', 'data': {'output': ChatPromptValue(messages=[HumanMessage(content='講一個早安問候語關於 父母親')])}, 'run_id': 'b09f31c9-63e0-4486-bf54-f08827a01404', 'name': 'ChatPromptTemplate', 'tags': ['seq:step:1'], 'metadata': {}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='講一個早安問候語關於 父母親')]]}}, 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='早', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='安', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='！', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='感', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='恩', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='父', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='母', id='run-c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed')}, 'run_id': 'c6b94b7d-4b6e-449f-ac35-0d9d7fed78ed', 'name': 'OAI_MODEL_GPT3.5', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['fff93ec9-75f8-4e90-b829-c1c6f32c5c1a']}\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 結論\n",
        "\n",
        "通過本教程，我們深入探討了 LangChain 的串流功能，從基本的 invoke 和 stream 方法，到更高級的事件串流和過濾技術。這些工具和技巧將幫助你構建更加靈活、高效的 AI 應用，提供更好的用戶體驗。記住，選擇合適的串流方法取決於你的具體需求和應用場景。持續實踐和探索，你將能夠充分發揮這些強大功能的潛力！\n",
        "\n",
        "關鍵takeaways：\n",
        "\n",
        "- 串流技術對於提升AI應用的響應性至關重要\n",
        "- LangChain提供了多種串流方法，適用於不同場景\n",
        "- 事件串流API允許更細粒度的控制和監控\n",
        "- 合理使用過濾技術可以優化串流事件的處理效率"
      ],
      "metadata": {
        "id": "BDobn8Kot1EE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph 串流應用：探索高效的資料處理方案\n",
        "\n",
        "在現代資料處理和人工智慧應用中,串流（Streaming）技術扮演著越來越重要的角色。它能夠實時處理大量數據,提高系統的響應速度和效率。本文將深入探討 LangGraph 提供的串流功能,為您揭示其強大的應用潛力。\n"
      ],
      "metadata": {
        "id": "dOaVpCZHyxWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangGraph 串流模式概覽\n",
        "\n",
        "LangGraph 支持多種串流模式,其中最主要的兩種是:\n",
        "\n",
        "1. `values`: 此模式會串流回圖的值,即每個節點調用後圖的完整狀態。\n",
        "2. `updates`: 此模式會串流回圖的更新,即每個節點調用後圖狀態的變化。\n",
        "\n",
        "這些模式為開發者提供了靈活的選擇,以適應不同的應用場景和需求。"
      ],
      "metadata": {
        "id": "6zLl2CWavpn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境準備\n",
        "\n",
        "首先,讓我們安裝必要的套件並確認版本:"
      ],
      "metadata": {
        "id": "Y-BCkKF3vwAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet langgraph"
      ],
      "metadata": {
        "id": "b1peZj4i0Wk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "確認一下 LangGraph 版本號"
      ],
      "metadata": {
        "id": "0C4h7wON1cRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWcnUwgU1c5P",
        "outputId": "648b8abf-865c-476f-ccb2-f95952eddb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langgraph\n",
            "Version: 0.2.4\n",
            "Summary: Building stateful, multi-actor applications with LLMs\n",
            "Home-page: https://www.github.com/langchain-ai/langgraph\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: langchain-core, langgraph-checkpoint\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 提示：確保您使用的 LangGraph 版本，版本更新迅速有時候 API 會改變。確認正確版本,以獲得最佳的功能支持和性能優化。\n",
        "\n"
      ],
      "metadata": {
        "id": "hNaOyrTXv05i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 深入探索：串流全狀態(full state)方法"
      ],
      "metadata": {
        "id": "nTyuPFKR2Xq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 準備工作：定義工具和模型\n",
        "首先,我們需要定義一些基本元素:\n"
      ],
      "metadata": {
        "id": "MDcCWS7CwEBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "@tool\n",
        "def recommend_night_market_food(preference: Literal[\"鹹食\", \"甜食\"]):\n",
        "    \"\"\"推薦夜市小吃。\"\"\"\n",
        "    if preference == \"鹹食\":\n",
        "        return \"推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！\"\n",
        "    elif preference == \"甜食\":\n",
        "        return \"來一份寧夏夜市的圓仔冰如何？Q彈的湯圓搭配清涼冰品，超級消暑！\"\n",
        "    else:\n",
        "        raise AssertionError(\"未知偏好\")\n",
        "\n",
        "@tool\n",
        "def recommend_bubble_tea(style: Literal[\"傳統\", \"創新\"]):\n",
        "    \"\"\"推薦手搖飲。\"\"\"\n",
        "    if style == \"傳統\":\n",
        "        return \"你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！\"\n",
        "    elif style == \"創新\":\n",
        "        return \"試試看西門町的芋圓冰沙拿鐵，結合了傳統芋圓和現代咖啡，口感層次豐富！\"\n",
        "    else:\n",
        "        raise AssertionError(\"未知風格\")\n",
        "\n",
        "tools = [recommend_night_market_food, recommend_bubble_tea]\n",
        "\n",
        "model = ChatOpenAI(temperature=0)\n",
        "graph = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "FWLNFxKmYXKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在這個設置中,我們定義了兩個簡單的美食查詢工具和一個 ChatOpenAI 模型。這些元素將用於構建我們的 LangGraph 應用。"
      ],
      "metadata": {
        "id": "YW4Z2rBNwxSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 串流值（Stream values）\n",
        "現在,讓我們看看如何使用 values 模式進行串流:"
      ],
      "metadata": {
        "id": "EwKZK5vs2nTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [(\"human\", \"我想吃夜市的小吃，有什麼推薦嗎？\")]}\n",
        "async for chunk in graph.astream(inputs, stream_mode=\"values\"):\n",
        "    #顯示最新訊息的內容，並且漂亮顯示出\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX_tVUkM1RUS",
        "outputId": "7bf964cc-2bf3-4587-a165-f5cb41dfbc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我想吃夜市的小吃，有什麼推薦嗎？\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  recommend_night_market_food (call_E1u0AVBv8KNztnArzucF0aXm)\n",
            " Call ID: call_E1u0AVBv8KNztnArzucF0aXm\n",
            "  Args:\n",
            "    preference: 鹹食\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: recommend_night_market_food\n",
            "\n",
            "推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "我推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "這段代碼將實時顯示圖的完整狀態,讓您能夠觀察到整個處理過程。\n",
        "\n",
        "> 提醒：如果只想拿到最後 Agent 生成的結果，在相同模式下只要獲取最新也就是最後一個 chunk 就可以了呦\n"
      ],
      "metadata": {
        "id": "H_XYf2c2zb8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [(\"human\", \"有什麼手搖飲推薦嗎？\")]}\n",
        "async for chunk in graph.astream(inputs, stream_mode=\"values\"):\n",
        "    final_result = chunk\n",
        "\n",
        "final_result[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pUBeJza1rJ3",
        "outputId": "6f473101-3543-4c96-b73a-02e5c42e834c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "我推薦你試試台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 串流狀態更新(stream state updates)範例\n",
        "\n",
        "除了獲取完整狀態,我們還可以關注節點狀態的變化:\n"
      ],
      "metadata": {
        "id": "tHH1Mgj12qcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [(\"human\", \"我想喝夜市的特色飲料，該去哪裡？\")]}\n",
        "async for chunk in graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"接收來自節點 '{node}' 的更新:\")\n",
        "        values[\"messages\"][-1].pretty_print()\n",
        "        # print(values)\n",
        "        # print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLgBmZlu2qMZ",
        "outputId": "f363f119-e9c2-491a-eae5-0d713022275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "接收來自節點 'agent' 的更新:\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  recommend_bubble_tea (call_KJQJXtV6aOmG2bdrU8uKPNAn)\n",
            " Call ID: call_KJQJXtV6aOmG2bdrU8uKPNAn\n",
            "  Args:\n",
            "    style: 傳統\n",
            "接收來自節點 'tools' 的更新:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: recommend_bubble_tea\n",
            "\n",
            "你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！\n",
            "接收來自節點 'agent' 的更新:\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "我建議你去台中第四信用合作社對面的夜市，試試他們的珍珠奶茶，香濃滑順，珍珠有嚼勁！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "這種方法讓您能夠精確地追踪每個節點的變化,對於調試和優化非常有用。"
      ],
      "metadata": {
        "id": "9x0BrOIJzpf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 提示：可以注意到 `values` 與 `updates` 兩者在使用上的差異。想要知道 Message 的狀態的話選 `values`，想要關注每個節點的狀態的話，選擇 `updates`"
      ],
      "metadata": {
        "id": "gwww4VHax0XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 多模式串流配置示例\n",
        "若想要同時取得的話，直接在 astream() 當中的 stream_mode 當中填入即可"
      ],
      "metadata": {
        "id": "9Z2z29FE3quK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [(\"human\", \"請推薦一個夜市的小吃和一個飲料\")]}\n",
        "async for event, chunk in graph.astream(inputs, stream_mode=[\"values\", \"updates\", \"debug\"]):\n",
        "    print(f\"接收新的事件類型: {event}...\")\n",
        "    print(chunk)\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdA6C9JB2v8x",
        "outputId": "879ff3b2-6c7a-4fc6-f4b2-c20a0c2f0322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "接收新的事件類型: values...\n",
            "{'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a')]}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: debug...\n",
            "{'type': 'task', 'timestamp': '2024-08-20T08:00:08.440204+00:00', 'step': 1, 'payload': {'id': '8399d8fd-4b28-515a-b0e9-1679557c0953', 'name': 'agent', 'input': {'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a')], 'is_last_step': False}, 'triggers': ['start:agent']}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: updates...\n",
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192})]}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: debug...\n",
            "{'type': 'task_result', 'timestamp': '2024-08-20T08:00:09.866295+00:00', 'step': 1, 'payload': {'id': '8399d8fd-4b28-515a-b0e9-1679557c0953', 'name': 'agent', 'result': [('messages', [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192})])]}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: values...\n",
            "{'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192})]}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: debug...\n",
            "{'type': 'task', 'timestamp': '2024-08-20T08:00:09.867006+00:00', 'step': 2, 'payload': {'id': 'f22971bf-6eff-55a2-84ab-fb97f629b133', 'name': 'tools', 'input': {'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192})], 'is_last_step': False}, 'triggers': ['branch:agent:should_continue:tools']}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: updates...\n",
            "{'tools': {'messages': [ToolMessage(content='推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！', name='recommend_night_market_food', tool_call_id='call_FJbZkH4jjcptgOvowqrxE3lZ'), ToolMessage(content='你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！', name='recommend_bubble_tea', tool_call_id='call_mUI7JW2ezK6rS2Hfwt6o2m2h')]}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: debug...\n",
            "{'type': 'task_result', 'timestamp': '2024-08-20T08:00:09.876344+00:00', 'step': 2, 'payload': {'id': 'f22971bf-6eff-55a2-84ab-fb97f629b133', 'name': 'tools', 'result': [('messages', [ToolMessage(content='推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！', name='recommend_night_market_food', tool_call_id='call_FJbZkH4jjcptgOvowqrxE3lZ'), ToolMessage(content='你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！', name='recommend_bubble_tea', tool_call_id='call_mUI7JW2ezK6rS2Hfwt6o2m2h')])]}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: values...\n",
            "{'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192}), ToolMessage(content='推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！', name='recommend_night_market_food', id='87e3babc-345c-4597-b09f-0821c0b4afba', tool_call_id='call_FJbZkH4jjcptgOvowqrxE3lZ'), ToolMessage(content='你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！', name='recommend_bubble_tea', id='33489aff-3f4a-4bcb-9f6a-fa36fe9b9bf3', tool_call_id='call_mUI7JW2ezK6rS2Hfwt6o2m2h')]}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: debug...\n",
            "{'type': 'task', 'timestamp': '2024-08-20T08:00:09.878316+00:00', 'step': 3, 'payload': {'id': '3e1a91b9-b94c-56a7-ace5-6fd8ee73fe8d', 'name': 'agent', 'input': {'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192}), ToolMessage(content='推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！', name='recommend_night_market_food', id='87e3babc-345c-4597-b09f-0821c0b4afba', tool_call_id='call_FJbZkH4jjcptgOvowqrxE3lZ'), ToolMessage(content='你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！', name='recommend_bubble_tea', id='33489aff-3f4a-4bcb-9f6a-fa36fe9b9bf3', tool_call_id='call_mUI7JW2ezK6rS2Hfwt6o2m2h')], 'is_last_step': False}, 'triggers': ['tools']}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: updates...\n",
            "{'agent': {'messages': [AIMessage(content='我推薦你試試「鹽酥雞」，外皮酥脆內多汁，是台北知名小吃！另外，你也可以品嚐一下台中第四信用合作社的珍珠奶茶，香濃滑順，珍珠有嚼勁！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 442, 'total_tokens': 541}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dcd51b98-7c2c-4e6c-be8f-e86397a18dc1-0', usage_metadata={'input_tokens': 442, 'output_tokens': 99, 'total_tokens': 541})]}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: debug...\n",
            "{'type': 'task_result', 'timestamp': '2024-08-20T08:00:11.925383+00:00', 'step': 3, 'payload': {'id': '3e1a91b9-b94c-56a7-ace5-6fd8ee73fe8d', 'name': 'agent', 'result': [('messages', [AIMessage(content='我推薦你試試「鹽酥雞」，外皮酥脆內多汁，是台北知名小吃！另外，你也可以品嚐一下台中第四信用合作社的珍珠奶茶，香濃滑順，珍珠有嚼勁！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 442, 'total_tokens': 541}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dcd51b98-7c2c-4e6c-be8f-e86397a18dc1-0', usage_metadata={'input_tokens': 442, 'output_tokens': 99, 'total_tokens': 541})])]}}\n",
            "\n",
            "\n",
            "\n",
            "接收新的事件類型: values...\n",
            "{'messages': [HumanMessage(content='請推薦一個夜市的小吃和一個飲料', id='81afad3c-ec07-4a6d-8984-c83a3bdb871a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'function': {'arguments': '{\"preference\": \"鹹食\"}', 'name': 'recommend_night_market_food'}, 'type': 'function'}, {'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'function': {'arguments': '{\"style\": \"傳統\"}', 'name': 'recommend_bubble_tea'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 132, 'total_tokens': 192}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d0dba6c-e50a-4bb3-8a5c-777e2f17fb15-0', tool_calls=[{'name': 'recommend_night_market_food', 'args': {'preference': '鹹食'}, 'id': 'call_FJbZkH4jjcptgOvowqrxE3lZ', 'type': 'tool_call'}, {'name': 'recommend_bubble_tea', 'args': {'style': '傳統'}, 'id': 'call_mUI7JW2ezK6rS2Hfwt6o2m2h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 60, 'total_tokens': 192}), ToolMessage(content='推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！', name='recommend_night_market_food', id='87e3babc-345c-4597-b09f-0821c0b4afba', tool_call_id='call_FJbZkH4jjcptgOvowqrxE3lZ'), ToolMessage(content='你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！', name='recommend_bubble_tea', id='33489aff-3f4a-4bcb-9f6a-fa36fe9b9bf3', tool_call_id='call_mUI7JW2ezK6rS2Hfwt6o2m2h'), AIMessage(content='我推薦你試試「鹽酥雞」，外皮酥脆內多汁，是台北知名小吃！另外，你也可以品嚐一下台中第四信用合作社的珍珠奶茶，香濃滑順，珍珠有嚼勁！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 442, 'total_tokens': 541}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dcd51b98-7c2c-4e6c-be8f-e86397a18dc1-0', usage_metadata={'input_tokens': 442, 'output_tokens': 99, 'total_tokens': 541})]}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "這種多模式配置為開發者提供了全方位的數據洞察,有助於更深入地理解和優化您的應用。"
      ],
      "metadata": {
        "id": "ZDZvPilRztOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 從最終節點串流\n",
        "\n",
        "在許多情況下,我們可能只對最終結果感興趣。以下示例展示了如何從最終節點串流 LLM 標記:\n"
      ],
      "metadata": {
        "id": "KlzeRL9W4de_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定義模型和工具\n"
      ],
      "metadata": {
        "id": "t_wTenk5sQFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "@tool\n",
        "def recommend_night_market_food(preference: Literal[\"鹹食\", \"甜食\"]):\n",
        "    \"\"\"推薦夜市小吃。\"\"\"\n",
        "    if preference == \"鹹食\":\n",
        "        return \"推薦你試試饒河夜市的胡椒餅，外皮酥脆內餡多汁，是台北知名小吃！\"\n",
        "    elif preference == \"甜食\":\n",
        "        return \"來一份寧夏夜市的圓仔冰如何？Q彈的湯圓搭配清涼冰品，超級消暑！\"\n",
        "    else:\n",
        "        raise AssertionError(\"未知偏好\")\n",
        "\n",
        "@tool\n",
        "def recommend_bubble_tea(style: Literal[\"傳統\", \"創新\"]):\n",
        "    \"\"\"推薦手搖飲。\"\"\"\n",
        "    if style == \"傳統\":\n",
        "        return \"你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！\"\n",
        "    elif style == \"創新\":\n",
        "        return \"試試看西門町的芋圓冰沙拿鐵，結合了傳統芋圓和現代咖啡，口感層次豐富！\"\n",
        "    else:\n",
        "        raise AssertionError(\"未知風格\")\n",
        "\n",
        "tools = [recommend_night_market_food, recommend_bubble_tea]\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "final_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "model = model.bind_tools(tools)\n",
        "# NOTE: this is where we're adding a tag that we'll be using later to filter the outputs of the final node\n",
        "final_model = final_model.with_config(tags=[\"final_node\"])"
      ],
      "metadata": {
        "id": "vkx81HQY3uLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "tool_node = ToolNode(tools=tools)"
      ],
      "metadata": {
        "id": "r9ef0rpHsWbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定義節點函數"
      ],
      "metadata": {
        "id": "wTIvuAUusZWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.graph.message import MessagesState\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"final\"]:\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return \"final\"\n",
        "\n",
        "def call_model(state: MessagesState):\n",
        "    messages = state[\"messages\"]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def call_final_model(state: MessagesState):\n",
        "    messages = state[\"messages\"]\n",
        "    last_ai_message = messages[-1]\n",
        "    response = final_model.invoke(\n",
        "        [\n",
        "            SystemMessage(\"美食部落客的口吻重新表達\"),\n",
        "            HumanMessage(last_ai_message.content),\n",
        "        ]\n",
        "    )\n",
        "    response.id = last_ai_message.id\n",
        "    return {\"messages\": [response]}\n"
      ],
      "metadata": {
        "id": "tAQFxxu6sX3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定義圖結構"
      ],
      "metadata": {
        "id": "T_RlsqIL0Xod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(MessagesState)\n",
        "\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"tools\", tool_node)\n",
        "workflow.add_node(\"final\", call_final_model)\n",
        "\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "workflow.add_edge(\"final\", END)\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "TxdLlrdUs0Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "zTh2Ls69s8zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "G8M3iv3Hs7jX",
        "outputId": "ac22d41a-bc88-499b-9ade-de805db91201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "然後，我們可以從最終節點獲取串流輸出："
      ],
      "metadata": {
        "id": "0QMjffOWtBDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [(\"human\", \"請推薦一款傳統手搖飲\")]}\n",
        "async for chunk in app.astream(inputs, stream_mode=\"values\"):\n",
        "    #顯示最新訊息的內容，並且漂亮顯示出\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5xSl7WO1246",
        "outputId": "69b2913e-8b7e-4578-b7b7-89b19e84b69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "請推薦一款傳統手搖飲\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  recommend_bubble_tea (call_sBFKwxoWFx1VAw9fsbnUOeaC)\n",
            " Call ID: call_sBFKwxoWFx1VAw9fsbnUOeaC\n",
            "  Args:\n",
            "    style: 傳統\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: recommend_bubble_tea\n",
            "\n",
            "你一定要品嚐一下台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "我推薦你品嚐台中第四信用合作社對面的珍珠奶茶，香濃滑順，珍珠有嚼勁！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "嘿嘿，我絕對要向大家推薦一下！別錯過台中第四信用合作社對面的珍珠奶茶喔！這杯奶茶香氣濃郁，口感滑順，還有那顆Q彈的珍珠，絕對讓你愛不釋手！快來一嚐，絕對不會讓你失望的！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "結論\n",
        "通過本教程，我們深入探討了 LangChain 和 LangGraph 的串流功能，從基本的 invoke 和 stream 方法，到更高級的事件串流和過濾技術。這些工具和技巧將幫助你構建更加靈活、高效的 AI 應用，提供卓越的用戶體驗。\n",
        "關鍵takeaways：\n",
        "\n",
        "串流技術對於提升 AI 應用的響應性至關重要\n",
        "LangChain 和 LangGraph 提供了多種串流方法，適用於不同場景\n",
        "事件串流 API 允許更細粒度的控制和監控\n",
        "合理使用過濾技術可以優化串流事件的處理效率\n",
        "選擇適當的串流模式（values 或 updates）可以根據需求獲取不同層面的信息"
      ],
      "metadata": {
        "id": "toJUfUZM3ZqU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMTCCGfw2aCW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}